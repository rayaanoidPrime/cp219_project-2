{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac797e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import algos\n",
    "import os\n",
    "import importlib.util\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b6ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('/home/mahalakshmi/Journal_May2025/SV_dec/SV Dataset/algos') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22604bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGO_FILES = [\n",
    "    # \"ae.py\",\n",
    "    # \"vae.py\",\n",
    "    \"optics.py\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92175e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing: optics ---\n",
      "Starting optics Workflow...\n",
      "Results will be saved to: /home/mahalakshmi/Journal_May2025/SV_dec/SV Dataset/NEW_results/results_aggregate/aggregated_optics_results.csv\n",
      "\n",
      "========================================\n",
      "Processing Attack: replay\n",
      "========================================\n",
      "\n",
      "=== Dataset for attack: replay ===\n",
      "Shapes (train, val, test):\n",
      "(70000, 54) (15000, 54) (15000, 54)\n",
      "Attack counts (train/val/test):\n",
      "attack\n",
      "0    56000\n",
      "1    14000\n",
      "Name: count, dtype: int64\n",
      "attack\n",
      "0    12000\n",
      "1     3000\n",
      "Name: count, dtype: int64\n",
      "attack\n",
      "0    12000\n",
      "1     3000\n",
      "Name: count, dtype: int64\n",
      "Numeric cols are:\n",
      "Index(['sv.length', 'sv.noASDU', 'sv.seqASDU', 'sv.smpCnt', 'sv.confRev',\n",
      "       'sv.smpSynch', 'sv.current_measurement_phase_1',\n",
      "       'sv.current_quality_phase_1', 'sv.current_measurement_phase_2',\n",
      "       'sv.current_quality_phase_2', 'sv.current_measurement_phase_3',\n",
      "       'sv.current_quality_phase_3', 'sv.current_measurement_4_derived',\n",
      "       'sv.current_quality_4_derived', 'sv.voltage_measurement_phase_1',\n",
      "       'sv.voltage_quality_phase_1', 'sv.voltage_measurement_phase_2',\n",
      "       'sv.voltage_quality_phase_2', 'sv.voltage_measurement_phase_3',\n",
      "       'sv.voltage_quality_phase_3', 'sv.voltage_measurement_4_derived',\n",
      "       'sv.voltage_quality_4_derived', 'frame_length', 'timestamp_delta'],\n",
      "      dtype='object')\n",
      "Ok\n",
      "Train: (70000, 24), Val: (15000, 24), Test: (15000, 24)\n",
      "Features used: 24\n",
      "  > Executing Run_1...\n",
      "Running model function in optics...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "import preprocessed \n",
    "\n",
    "\n",
    "sys.path.append('/home/mahalakshmi/Journal_May2025/SV_dec/SV Dataset/NEW_results/')\n",
    "\n",
    "try:\n",
    "    import utility.resource_usage as ru\n",
    "    import utility.unsupervised_helper as uh\n",
    "    import utility.plot_helper as ph\n",
    "except ImportError:\n",
    "    print(\"CRITICAL ERROR: Could not import 'utility' modules.\")\n",
    "    print(\"Please check sys.path.append line in the script.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATASET_NAME = 'SV_Dataset'\n",
    "GOID = 'NA'\n",
    "ATTACK_LIST = [\"replay\", \"injection\"] \n",
    "NUM_RUNS = 1\n",
    "\n",
    "def predict(model, X):\n",
    "    y_pred = model.predict(X)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        try:\n",
    "            scores = model.predict_proba(X)[:, 1]\n",
    "        except:\n",
    "            scores = y_pred # Fallback\n",
    "    else:\n",
    "        scores = y_pred\n",
    "    return y_pred, scores\n",
    "\n",
    "def main():\n",
    "    # Setup Output Directory\n",
    "    root_output_dir = uh.ROOT_OUTPUT_DIR\n",
    "    os.makedirs(root_output_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # ================= ITERATE OVER ATTACKS =================\n",
    "    for file_name in ALGO_FILES:\n",
    "        file_path = folder_path / file_name\n",
    "        module_name = file_path.stem \n",
    "        print(f\"--- Processing: {module_name} ---\")\n",
    "        \n",
    "        ALGO_NAME = module_name\n",
    "        agg_csv_path = f'{root_output_dir}/aggregated_{ALGO_NAME}_results.csv'\n",
    "        long_csv_path = os.path.join(uh.PLOT_DATA_DIR, f\"{ALGO_NAME}_metrics_long.csv\")\n",
    "        if os.path.exists(agg_csv_path):\n",
    "            os.remove(agg_csv_path)\n",
    "\n",
    "        print(f\"Starting {ALGO_NAME} Workflow...\")\n",
    "        print(f\"Results will be saved to: {agg_csv_path}\")\n",
    "        for attack_name in ATTACK_LIST:\n",
    "            print(f\"\\n{'='*40}\")\n",
    "            print(f\"Processing Attack: {attack_name}\")\n",
    "            print(f\"{'='*40}\")\n",
    "\n",
    "            try:\n",
    "                X_train, y_train, X_val, y_val, X_test, y_test, feats, y_orig = \\\n",
    "                    preprocessed.load_preprocessed_for_attack(attack_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading data for {attack_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "             # Get Counts\n",
    "            n_test_attack = np.sum(y_test == 1)\n",
    "            n_test_normal = np.sum(y_test == 0)\n",
    "            n_train_attack = np.sum(y_train == 1)\n",
    "            n_train_normal = np.sum(y_train == 0)\n",
    "\n",
    "            # Hierarchy info for the CSV\n",
    "            ds_info = {\n",
    "                'dataset': DATASET_NAME,\n",
    "                'goid': GOID,\n",
    "                'attack_type': attack_name\n",
    "            }\n",
    "\n",
    "            all_runs_results = {}\n",
    "\n",
    "            for i in range(1, NUM_RUNS + 1):\n",
    "                run_key = f\"Run_{i}\"\n",
    "                print(f\"  > Executing {run_key}...\")\n",
    "                try:\n",
    "                    \n",
    "                        spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "                        module = importlib.util.module_from_spec(spec)\n",
    "                        spec.loader.exec_module(module)\n",
    "                        print(f\"Running model function in {module_name}...\")\n",
    "                        # --- A. TRAINING (Profiled) ---\n",
    "                        \n",
    "                        with ru.ResourceProfiler() as profiler_train:\n",
    "                            model_instance = module.model(X_train, y_train, X_val, y_val)\n",
    "                        \n",
    "                        avg_train_wall_ns = profiler_train.wall_nanoseconds\n",
    "                        avg_time_pkt_tr = avg_train_wall_ns / len(y_train) if len(y_train) else 0\n",
    "\n",
    "                        # --- B. TESTING (Profiled) ---\n",
    "                        with ru.ResourceProfiler() as profiler_test:\n",
    "                            y_test_pred, scores = predict(model_instance, X_test)\n",
    "                        if set(np.unique(y_test_pred)) == {-1, 1}:\n",
    "                            y_test_pred = np.where(y_test_pred == -1, 0, 1)\n",
    "\n",
    "                        if scores is not None and np.min(scores) < 0:\n",
    "                            scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores) + 1e-9)\n",
    "                        \n",
    "                        avg_test_wall_ns = profiler_test.wall_nanoseconds\n",
    "                        avg_time_pkt_te = avg_test_wall_ns / len(y_test) if len(y_test) else 0\n",
    "\n",
    "                        # --- C. METRICS ---\n",
    "                        cm = confusion_matrix(y_test, y_test_pred, labels=[0, 1])\n",
    "                        tn, fp, fn, tp = cm.ravel()\n",
    "                        \n",
    "                        rpt = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "                        \n",
    "                        # Calculate advanced metrics\n",
    "                        precision_anom = precision_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "                        recall_anom    = recall_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "                        f1_anom        = f1_score(y_test, y_test_pred, pos_label=1, zero_division=0)\n",
    "                        balanced_acc   = balanced_accuracy_score(y_test, y_test_pred)\n",
    "                        mcc            = matthews_corrcoef(y_test, y_test_pred)\n",
    "                        roc_auc        = roc_auc_score(y_test, scores)\n",
    "                        pr_auc         = average_precision_score(y_test, scores)\n",
    "\n",
    "                        # --- D. BUILD JSON (Exact format as DT_reference.py) ---\n",
    "                        test_json = {\n",
    "                            \"Normal count\"          : int(n_test_normal),\n",
    "                            \"Attack count\"          : int(n_test_attack),\n",
    "                            \"Total\"                 : int(n_test_normal + n_test_attack),\n",
    "                            \"tp\"                    : int(tp),\n",
    "                            \"tn\"                    : int(tn),\n",
    "                            \"fp\"                    : int(fp),\n",
    "                            \"fn\"                    : int(fn),\n",
    "                            \"Accuracy %\"            : uh.r2(rpt['accuracy']*100),\n",
    "                            \"Precision_anom %\"      : uh.r2(precision_anom*100),\n",
    "                            \"Precision %\"           : uh.r2(rpt[\"macro avg\"][\"precision\"]*100),\n",
    "                            \"Recall_anom %\"         : uh.r2(recall_anom*100),\n",
    "                            \"Recall %\"              : uh.r2(rpt[\"macro avg\"][\"recall\"]*100),\n",
    "                            \"F1-Score_anom %\"       : uh.r2(f1_anom*100),\n",
    "                            \"F1-Score %\"            : uh.r2(rpt[\"macro avg\"][\"f1-score\"]*100),\n",
    "                            \"BalancedAcc %\"         : uh.r2(balanced_acc*100),\n",
    "                            \"MCC\"                   : uh.r3(mcc),\n",
    "                            \"PR-AUC\"                : uh.r3(pr_auc*100),\n",
    "                            \"ROC-AUC\"               : uh.r3(roc_auc*100),\n",
    "                            \n",
    "                            # Resource Metrics\n",
    "                            \"TotalTime (ms)\"        : uh.r3(avg_test_wall_ns / 1_000_000),\n",
    "                            \"AvgTimePerPacket(ns)\"  : uh.r3(avg_time_pkt_te),\n",
    "                            \"Ram_usage\"             : uh.r3(profiler_test.peak_ram_mb),\n",
    "                            \"CPU_avg%\"              : uh.r3(profiler_test.cpu_avg_machine_pct),\n",
    "                            \"CPU_peak%\"             : uh.r3(profiler_test.cpu_peak_machine_pct),\n",
    "                            \n",
    "                            # Training Metrics\n",
    "                            \"training_time_ms\"      : uh.r3(avg_train_wall_ns / 1_000_000),\n",
    "                            \"training_avg_time_per_packet_ns\": uh.r3(avg_time_pkt_tr),\n",
    "                            \"training_peak_ram_mb\"  : uh.r3(profiler_train.peak_ram_mb),\n",
    "                            \"training_cpu_avg_pct\"  : uh.r3(profiler_train.cpu_avg_machine_pct),\n",
    "                            \"training_cpu_peak_pct\" : uh.r3(profiler_train.cpu_peak_machine_pct),\n",
    "                            \"n_train_attack\"        : int(n_train_attack),\n",
    "                            \"n_train_normal\"        : int(n_train_normal)     \n",
    "                        }\n",
    "\n",
    "                        all_runs_results[run_key] = {\n",
    "                            \"Test\": test_json\n",
    "                        }\n",
    "                        # ================= SAVE RESULTS =================\n",
    "                        uh.append_results_to_csv(agg_csv_path, all_runs_results, ds_info)\n",
    "\n",
    "                        rows = uh.extract_plot_rows(all_runs_results, ALGO_NAME, ds_info) + \\\n",
    "                        uh.extract_average_rows_over_runs(all_runs_results, ALGO_NAME, ds_info)\n",
    "            \n",
    "                        uh.append_rows_to_long_csv(long_csv_path, rows)\n",
    "            \n",
    "                        print(f\"  [Saved] Results for {attack_name} saved.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in Run {i}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "\n",
    "        \n",
    "\n",
    "    print(\"\\nWorkflow Completed.\")\n",
    "    print(f\"Aggregated results: {agg_csv_path}\")\n",
    "    # print(f\"Plotting data: {long_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bff56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
